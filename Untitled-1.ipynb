{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three datasets:\n",
    "\n",
    "- nimi pi - a dataset of toki pona words to several possible english translations\n",
    "- word freq - english words along with part of speech, sorted by frequency. We can approximate this with Zipf's law.\n",
    "- conceptnetw2v - a word vectorization based on semantic meaning. This will allow us to decide between candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = pd.read_csv(\"conceptnetw2v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.read_csv(\"word-freq-top5000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "toki = pd.read_csv(\"nimi_pi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKI</th>\n",
       "      <th>PART_OF_SPEECH</th>\n",
       "      <th>ENG1</th>\n",
       "      <th>ENG2</th>\n",
       "      <th>ENG3</th>\n",
       "      <th>ENG4</th>\n",
       "      <th>ENG5</th>\n",
       "      <th>ENG6</th>\n",
       "      <th>ENG7</th>\n",
       "      <th>ENG8</th>\n",
       "      <th>ENG9</th>\n",
       "      <th>ENG10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anpa</td>\n",
       "      <td>adjective</td>\n",
       "      <td>low</td>\n",
       "      <td>lower</td>\n",
       "      <td>bottom</td>\n",
       "      <td>down</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>anpa</td>\n",
       "      <td>adverb</td>\n",
       "      <td>downstairs</td>\n",
       "      <td>below</td>\n",
       "      <td>deep</td>\n",
       "      <td>low</td>\n",
       "      <td>deeply</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>anpa</td>\n",
       "      <td>noun</td>\n",
       "      <td>bottom</td>\n",
       "      <td>lower part</td>\n",
       "      <td>under</td>\n",
       "      <td>below</td>\n",
       "      <td>floor</td>\n",
       "      <td>beneath</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>anpa</td>\n",
       "      <td>verb intransitive</td>\n",
       "      <td>to prostrate oneself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOKI     PART_OF_SPEECH                   ENG1        ENG2    ENG3   ENG4  \\\n",
       "19  anpa          adjective                    low       lower  bottom  down    \n",
       "20  anpa             adverb             downstairs       below    deep    low   \n",
       "21  anpa               noun                 bottom  lower part   under  below   \n",
       "22  anpa  verb intransitive  to prostrate oneself          NaN     NaN    NaN   \n",
       "\n",
       "       ENG5      ENG6 ENG7 ENG8 ENG9  ENG10  \n",
       "19      NaN       NaN  NaN  NaN  NaN    NaN  \n",
       "20  deeply        NaN  NaN  NaN  NaN    NaN  \n",
       "21    floor  beneath   NaN  NaN  NaN    NaN  \n",
       "22      NaN       NaN  NaN  NaN  NaN    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toki[toki.TOKI == 'anpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Word</th>\n",
       "      <th>Part of speech</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Dispersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>Article</td>\n",
       "      <td>22038615</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>Article</td>\n",
       "      <td>10144200</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>his</td>\n",
       "      <td>Article</td>\n",
       "      <td>1801708</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>their</td>\n",
       "      <td>Article</td>\n",
       "      <td>1083029</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>her</td>\n",
       "      <td>Article</td>\n",
       "      <td>969591</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>my</td>\n",
       "      <td>Article</td>\n",
       "      <td>919821</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>your</td>\n",
       "      <td>Article</td>\n",
       "      <td>659622</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>its</td>\n",
       "      <td>Article</td>\n",
       "      <td>539719</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>our</td>\n",
       "      <td>Article</td>\n",
       "      <td>525107</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>no</td>\n",
       "      <td>Article</td>\n",
       "      <td>402222</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>172</td>\n",
       "      <td>every</td>\n",
       "      <td>Article</td>\n",
       "      <td>212739</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank   Word Part of speech  Frequency  Dispersion\n",
       "0       1    the        Article   22038615        0.98\n",
       "4       5      a        Article   10144200        0.98\n",
       "24     25    his        Article    1801708        0.95\n",
       "35     36  their        Article    1083029        0.97\n",
       "41     42    her        Article     969591        0.91\n",
       "43     44     my        Article     919821        0.93\n",
       "68     69   your        Article     659622        0.94\n",
       "77     78    its        Article     539719        0.96\n",
       "78     79    our        Article     525107        0.97\n",
       "92     93     no        Article     402222        0.98\n",
       "171   172  every        Article     212739        0.97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[freq['Part of speech'] == 'Article']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " freq['Part of speech'].value_counts() ->\n",
    " Noun           2543 \n",
    " Verb           1001\n",
    " Adjective       838\n",
    " Adverb          342 <- We will ignore\n",
    " Preposition      97\n",
    " Pronoun          47\n",
    " Conjunction      38\n",
    " Measure          35\n",
    " Determiner       34\n",
    " Exclamation      13\n",
    " Article          11  <- We will ignore\n",
    " Exception         1  <- We will ignore\n",
    " Name: Part of speech, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = freq[freq['Part of speech'] == 'Noun']['Word'].tolist()\n",
    "verbs = freq[freq['Part of speech'] == 'Verb']['Word'].tolist()\n",
    "adjcs = freq[freq['Part of speech'] == 'Adjective']['Word'].tolist()\n",
    "preps = freq[freq['Part of speech'] == 'Preposition']['Word'].tolist()\n",
    "prons = freq[freq['Part of speech'] == 'Pronoun']['Word'].tolist()\n",
    "conjs = freq[freq['Part of speech'] == 'Conjunction']['Word'].tolist()\n",
    "detes = freq[freq['Part of speech'] == 'Determiner']['Word'].tolist()\n",
    "excls = freq[freq['Part of speech'] == 'Exclamation']['Word'].tolist()\n",
    "meass = freq[freq['Part of speech'] == 'Measure']['Word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two', 'first', 'last', 'three', 'next', 'million', 'four', 'five', 'second']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meass[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the continuum of experience in which events pass from the future through the present to the past; he waited for along time; it took some time before he got an answer; time flies like an arrow',\n",
       " \"a person's experience on a particular occasion; he had a time holding back the tears; they had a good time together\",\n",
       " 'an instance or single occasion for some event; this time he succeeded; he called four times; he could do ten at a clip',\n",
       " 'an indefinite period (usually marked by specific attributes or activities); the time of year for planting; he was a great actor in his time',\n",
       " 'a suitable moment; it is time to go',\n",
       " \"a period of time considered as a resource under your control and sufficient to accomplish something; take time to smell the roses; I didn't have time to finish; it took more than half my time; he waited for a long time\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = pd.read_csv(\"thesauri\\WordnetNouns.csv\")\n",
    "synonyms[synonyms.Word == 'time']['Definition'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDef = dict()\n",
    "for noun in nouns:\n",
    "    defs = synonyms[synonyms.Word == noun]['Definition'].tolist()\n",
    "    if len(defs) > 0:\n",
    "        defn = defs[0]\n",
    "        toDef[noun] = defn.split(';')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a piece of information about circumstances that exist or events that have occurred'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDef['fact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warm-blooded egg-laying vertebrates characterized by feathers and forelimbs modified as wings'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDef['bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_vocab = toki.TOKI.drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'akesi',\n",
       " 'ala',\n",
       " 'alasa',\n",
       " 'ale',\n",
       " 'ali',\n",
       " 'anpa',\n",
       " 'ante',\n",
       " 'anu ',\n",
       " 'awen',\n",
       " 'en',\n",
       " 'esun',\n",
       " 'ijo',\n",
       " 'ike',\n",
       " 'ilo',\n",
       " 'insa',\n",
       " 'ipa',\n",
       " 'jaki',\n",
       " 'jan',\n",
       " 'jelo',\n",
       " 'jo',\n",
       " 'kala',\n",
       " 'kalama',\n",
       " 'kama',\n",
       " 'kama ',\n",
       " 'kasi',\n",
       " 'ken',\n",
       " 'ken ',\n",
       " 'kepeken',\n",
       " 'kepeken ',\n",
       " 'kili',\n",
       " 'kin',\n",
       " 'kipisi ',\n",
       " 'kipisi',\n",
       " 'kiwen',\n",
       " 'ko',\n",
       " 'kon',\n",
       " 'kule',\n",
       " 'kulupu',\n",
       " 'kute',\n",
       " 'la ',\n",
       " 'lape',\n",
       " 'laso',\n",
       " 'lawa',\n",
       " 'len',\n",
       " 'lete',\n",
       " 'lili',\n",
       " 'linja',\n",
       " 'lipu',\n",
       " 'loje',\n",
       " 'lon',\n",
       " 'lon ',\n",
       " 'luka',\n",
       " 'lukin',\n",
       " 'lukin ',\n",
       " 'lupa',\n",
       " 'ma',\n",
       " 'mama',\n",
       " 'mani',\n",
       " 'meli',\n",
       " 'mi',\n",
       " 'e mi',\n",
       " 'mije',\n",
       " 'moku',\n",
       " 'moli',\n",
       " 'monsi',\n",
       " 'monsuta',\n",
       " 'mu',\n",
       " 'mun',\n",
       " 'musi',\n",
       " 'mute',\n",
       " 'namako',\n",
       " 'nanpa ',\n",
       " 'nanpa',\n",
       " 'nasa',\n",
       " 'nasin',\n",
       " 'nena',\n",
       " 'ni',\n",
       " 'nimi',\n",
       " 'noka',\n",
       " 'noka ',\n",
       " 'o',\n",
       " 'oko',\n",
       " 'olin',\n",
       " 'ona',\n",
       " 'e ona',\n",
       " 'open',\n",
       " 'open ',\n",
       " 'pakala',\n",
       " 'pali',\n",
       " 'palisa',\n",
       " 'pan',\n",
       " 'pana',\n",
       " 'pi ',\n",
       " 'pilin',\n",
       " 'pimeja',\n",
       " 'pini',\n",
       " 'pini ',\n",
       " 'pipi',\n",
       " 'poka',\n",
       " 'poki',\n",
       " 'pona',\n",
       " 'pu',\n",
       " 'pu ',\n",
       " 'sama',\n",
       " 'sama ',\n",
       " 'seli',\n",
       " 'selo',\n",
       " 'seme',\n",
       " 'sewi',\n",
       " 'sijelo',\n",
       " 'sike',\n",
       " 'sin',\n",
       " 'sin ',\n",
       " 'sina',\n",
       " 'e sina',\n",
       " 'sinpin',\n",
       " 'sitelen',\n",
       " 'sona',\n",
       " 'sona ',\n",
       " 'soweli',\n",
       " 'suli',\n",
       " 'suno',\n",
       " 'supa',\n",
       " 'suwi',\n",
       " 'tan',\n",
       " 'tan ',\n",
       " 'taso',\n",
       " 'taso ',\n",
       " 'tawa',\n",
       " 'tawa ',\n",
       " 'telo',\n",
       " 'tenpo',\n",
       " 'toki',\n",
       " 'tomo',\n",
       " 'tu',\n",
       " 'unpa',\n",
       " 'uta',\n",
       " 'utala',\n",
       " 'walo',\n",
       " 'wan',\n",
       " 'waso',\n",
       " 'wawa',\n",
       " 'weka',\n",
       " 'wile',\n",
       " 'wile ']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict([(tp_vocab[i], []) for i in range(len(tp_vocab))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13408\\3249330483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'insane'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#[df.TOKI == 'soweli']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[df.word == 'insane'] #[df.TOKI == 'soweli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>...</th>\n",
       "      <th>col292</th>\n",
       "      <th>col293</th>\n",
       "      <th>col294</th>\n",
       "      <th>col295</th>\n",
       "      <th>col296</th>\n",
       "      <th>col297</th>\n",
       "      <th>col298</th>\n",
       "      <th>col299</th>\n",
       "      <th>col300</th>\n",
       "      <th>col301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105129</th>\n",
       "      <td>105129</td>\n",
       "      <td>crazy</td>\n",
       "      <td>-0.0887</td>\n",
       "      <td>-0.1246</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>-0.1771</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.0371</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0404</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0223</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   word    col1    col2    col3    col4   col5    col6  \\\n",
       "105129      105129  crazy -0.0887 -0.1246  0.1103 -0.1771  0.006 -0.0371   \n",
       "\n",
       "          col7   col8  ...  col292  col293  col294  col295  col296  col297  \\\n",
       "105129  0.0148 -0.033  ... -0.0404  0.0207  -0.017  0.0511 -0.0008 -0.0223   \n",
       "\n",
       "        col298  col299  col300  col301  \n",
       "105129  0.0092  0.0248  0.0145     NaN  \n",
       "\n",
       "[1 rows x 303 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.word == 'crazy'] #[df.TOKI == 'soweli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pd.read_csv('nimi_pi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKI</th>\n",
       "      <th>PART_OF_SPEECH</th>\n",
       "      <th>ENG1</th>\n",
       "      <th>ENG2</th>\n",
       "      <th>ENG3</th>\n",
       "      <th>ENG4</th>\n",
       "      <th>ENG5</th>\n",
       "      <th>ENG6</th>\n",
       "      <th>ENG7</th>\n",
       "      <th>ENG8</th>\n",
       "      <th>ENG9</th>\n",
       "      <th>ENG10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>interjection</td>\n",
       "      <td>ah</td>\n",
       "      <td>ha</td>\n",
       "      <td>uh</td>\n",
       "      <td>oh</td>\n",
       "      <td>ooh</td>\n",
       "      <td>aw</td>\n",
       "      <td>well (emotion word)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a a a!</td>\n",
       "      <td>interjection</td>\n",
       "      <td>laugh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akesi</td>\n",
       "      <td>adjective</td>\n",
       "      <td>amphibian-</td>\n",
       "      <td>reptilian-</td>\n",
       "      <td>slimy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akesi</td>\n",
       "      <td>noun</td>\n",
       "      <td>reptile</td>\n",
       "      <td>amphibian; non-cute animal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ala</td>\n",
       "      <td>adjective</td>\n",
       "      <td>no</td>\n",
       "      <td>not</td>\n",
       "      <td>none</td>\n",
       "      <td>un-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>weka</td>\n",
       "      <td>noun</td>\n",
       "      <td>absence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>weka (e )</td>\n",
       "      <td>verb transitive</td>\n",
       "      <td>to remove</td>\n",
       "      <td>to eliminate</td>\n",
       "      <td>to throw away</td>\n",
       "      <td>to get rid of</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>wile</td>\n",
       "      <td>noun</td>\n",
       "      <td>desire</td>\n",
       "      <td>need</td>\n",
       "      <td>will</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>wile (e )</td>\n",
       "      <td>verb transitive</td>\n",
       "      <td>to want</td>\n",
       "      <td>need</td>\n",
       "      <td>wish</td>\n",
       "      <td>have to</td>\n",
       "      <td>must</td>\n",
       "      <td>will</td>\n",
       "      <td>should</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>wile</td>\n",
       "      <td>auxiliary verb</td>\n",
       "      <td>to want</td>\n",
       "      <td>need</td>\n",
       "      <td>wish</td>\n",
       "      <td>have to</td>\n",
       "      <td>must</td>\n",
       "      <td>will</td>\n",
       "      <td>should</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKI   PART_OF_SPEECH        ENG1                         ENG2  \\\n",
       "0            a     interjection          ah                           ha   \n",
       "1       a a a!     interjection      laugh                           NaN   \n",
       "2        akesi        adjective  amphibian-                   reptilian-   \n",
       "3        akesi             noun     reptile  amphibian; non-cute animal    \n",
       "4          ala        adjective          no                          not   \n",
       "..         ...              ...         ...                          ...   \n",
       "422       weka             noun    absence                           NaN   \n",
       "423  weka (e )  verb transitive   to remove                 to eliminate   \n",
       "424       wile             noun      desire                         need   \n",
       "425  wile (e )  verb transitive     to want                         need   \n",
       "426      wile    auxiliary verb     to want                         need   \n",
       "\n",
       "              ENG3            ENG4  ENG5  ENG6                  ENG7 ENG8  \\\n",
       "0               uh              oh   ooh    aw  well (emotion word)   NaN   \n",
       "1              NaN             NaN   NaN   NaN                   NaN  NaN   \n",
       "2           slimy              NaN   NaN   NaN                   NaN  NaN   \n",
       "3              NaN             NaN   NaN   NaN                   NaN  NaN   \n",
       "4             none            un-    NaN   NaN                   NaN  NaN   \n",
       "..             ...             ...   ...   ...                   ...  ...   \n",
       "422            NaN             NaN   NaN   NaN                   NaN  NaN   \n",
       "423  to throw away  to get rid of    NaN   NaN                   NaN  NaN   \n",
       "424          will              NaN   NaN   NaN                   NaN  NaN   \n",
       "425           wish         have to  must  will               should   NaN   \n",
       "426           wish         have to  must  will               should   NaN   \n",
       "\n",
       "    ENG9  ENG10  \n",
       "0    NaN    NaN  \n",
       "1    NaN    NaN  \n",
       "2    NaN    NaN  \n",
       "3    NaN    NaN  \n",
       "4    NaN    NaN  \n",
       "..   ...    ...  \n",
       "422  NaN    NaN  \n",
       "423  NaN    NaN  \n",
       "424  NaN    NaN  \n",
       "425  NaN    NaN  \n",
       "426  NaN    NaN  \n",
       "\n",
       "[427 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1 col2 col3 col4 col5 col6 col7 col8 col9 col10 col11 col12 col13 col14 col15 col16 col17 col18 col19 col20 col21 col22 col23 col24 col25 col26 col27 col28 col29 col30 col31 col32 col33 col34 col35 col36 col37 col38 col39 col40 col41 col42 col43 col44 col45 col46 col47 col48 col49 col50 col51 col52 col53 col54 col55 col56 col57 col58 col59 col60 col61 col62 col63 col64 col65 col66 col67 col68 col69 col70 col71 col72 col73 col74 col75 col76 col77 col78 col79 col80 col81 col82 col83 col84 col85 col86 col87 col88 col89 col90 col91 col92 col93 col94 col95 col96 col97 col98 col99 col100 col101 col102 col103 col104 col105 col106 col107 col108 col109 col110 col111 col112 col113 col114 col115 col116 col117 col118 col119 col120 col121 col122 col123 col124 col125 col126 col127 col128 col129 col130 col131 col132 col133 col134 col135 col136 col137 col138 col139 col140 col141 col142 col143 col144 col145 col146 col147 col148 col149 col150 col151 col152 col153 col154 col155 col156 col157 col158 col159 col160 col161 col162 col163 col164 col165 col166 col167 col168 col169 col170 col171 col172 col173 col174 col175 col176 col177 col178 col179 col180 col181 col182 col183 col184 col185 col186 col187 col188 col189 col190 col191 col192 col193 col194 col195 col196 col197 col198 col199 col200 col201 col202 col203 col204 col205 col206 col207 col208 col209 col210 col211 col212 col213 col214 col215 col216 col217 col218 col219 col220 col221 col222 col223 col224 col225 col226 col227 col228 col229 col230 col231 col232 col233 col234 col235 col236 col237 col238 col239 col240 col241 col242 col243 col244 col245 col246 col247 col248 col249 col250 col251 col252 col253 col254 col255 col256 col257 col258 col259 col260 col261 col262 col263 col264 col265 col266 col267 col268 col269 col270 col271 col272 col273 col274 col275 col276 col277 col278 col279 col280 col281 col282 col283 col284 col285 col286 col287 col288 col289 col290 col291 col292 col293 col294 col295 col296 col297 col298 col299 col300 \n"
     ]
    }
   ],
   "source": [
    "f = \"\"\n",
    "for i in range(300):\n",
    "    f += f\"col{i+1} \"\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lps(ws: str):\n",
    "    table = [[0] * len(ws) for _ in range(len(ws))]\n",
    "    print(table)\n",
    "    for i in range(len(table)):\n",
    "        table[i][i] = 1\n",
    "    for gap in range(1, len(ws)):\n",
    "        for st in range(len(ws) - gap):\n",
    "            en = st + gap\n",
    "            if st == en:\n",
    "                table[st][en] = 1\n",
    "            if ws[st] == ws[en]:\n",
    "                table[st][en] = table[st + 1][en - 1] + 2\n",
    "            else:\n",
    "                table[st][en] = max(table[st + 1][en], table[st][en - 1])\n",
    "    \n",
    "    return table[0][len(ws) - 1]\n",
    "\n",
    "result = lps(\"mmmmm\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
